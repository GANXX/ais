{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a422e90-1dd5-466d-b166-726dbb967286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:23:49,285 - modelscope - INFO - PyTorch version 2.0.0 Found.\n",
      "2024-08-23 14:23:49,288 - modelscope - INFO - TensorFlow version 2.17.0 Found.\n",
      "2024-08-23 14:23:49,288 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-08-23 14:23:49,437 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 34cc0ab19a6bcca90022a212fc92f4a8 and a total number of 980 components indexed\n",
      "2024-08-23 14:23:50.152818: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-23 14:23:50.168393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-23 14:23:50.187422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-23 14:23:50.192728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-23 14:23:50.206364: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-23 14:23:51.281444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ganxin/fa/ais/workspace/questionB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab99a38ceb74c629723d7b814c2e42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer,TrainingArguments, DataCollatorForSeq2Seq, BitsAndBytesConfig\n",
    "import torch\n",
    "print(os.getcwd()) \n",
    "\n",
    "# import json\n",
    "from datasets import load_dataset\n",
    "from config import DATA_PATH, VAL_SET_SIZE, DATA_SET, MODEL, MODEL_PATH\n",
    "from utils import generate_prompt, data_collator, save_pretrained, print_trainable_parameters\n",
    "\n",
    "import os\n",
    "pwd = os.getcwd()\n",
    "cur_dir=os.path.dirname(pwd)\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "# 加载预训练模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained('/home/ganxin/fa/ais/workspace/data/questionBData/model/Lucachen/gemma2b', quantization_config=bnb_config, device_map=\"auto\",torch_dtype=torch.bfloat16)\n",
    "\n",
    "print(base_model)\n",
    "print(print_trainable_parameters(base_model))\n",
    "\n",
    "from peft import LoraConfig, TaskType, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "# 需要修改的lora参数\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\", \"lm_head\"],\n",
    "    inference_mode=False, # 训练模式\n",
    "    bias=\"none\",\n",
    "    r=8, # Lora 秩\n",
    "    lora_alpha=32, # Lora alaph，具体作用参见 Lora 原理\n",
    "    lora_dropout=0.1 # Dropout 比例\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, config)\n",
    "print(model)\n",
    "print(print_trainable_parameters(model))\n",
    "\n",
    "#需要调整的训练参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"%s/output/%s/%s\"%(cur_dir, MODEL, DATA_SET),\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3, \n",
    "    save_steps=100,\n",
    "    learning_rate=8e-5, # 1e-3 ~ 5e-5\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "# 读取数据集\n",
    "data = load_dataset(\"csv\", data_files=DATA_PATH , delimiter=\"\\t\")\n",
    "# 分为训练集，验证集，验证集不是必要\n",
    "if VAL_SET_SIZE > 0:\n",
    "    VAL_SET_SIZE = max(min(VAL_SET_SIZE, int(len(data)/10000)), 1)\n",
    "    generate_prompt(data[\"train\"][0], is_logger=True)\n",
    "    train_val = data[\"train\"].train_test_split(test_size=VAL_SET_SIZE, shuffle=True, seed=42)\n",
    "    train_data = train_val[\"train\"] .shuffle().map(generate_prompt)\n",
    "    val_data = train_val[\"test\"].shuffle().map(generate_prompt)\n",
    "else:\n",
    "    generate_prompt(data[\"train\"][0], is_logger=True)\n",
    "    train_data = data[\"train\"].shuffle().map(generate_prompt)\n",
    "    val_data = None\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_data,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "lora_path='%s/saved_model/%s'%(cur_dir, DATA_SET) # 修改成工作路径\n",
    "\n",
    "model.config.use_cache = True\n",
    "trainer.model.save_pretrained(lora_path)\n",
    "save_pretrained(lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861e312-ecf1-4e3f-a085-b67b8fbba5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762e1b1-95eb-4285-9fab-96b9dda7ef2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
